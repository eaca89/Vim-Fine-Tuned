{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eh_abdol/.conda/envs/vim/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datasets import DatasetDict\n",
    "from datasets import DatasetDict, Dataset, Features, ClassLabel, Value, Array3D\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForImageClassification, AutoFeatureExtractor\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_files(folder):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(folder):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                files.append(os.path.join(root, filename))\n",
    "    return files\n",
    "\n",
    "\n",
    "def load_images(folder):\n",
    "    class_names = sorted(os.listdir(folder))\n",
    "    data = []\n",
    "    for class_name in class_names:\n",
    "        class_folder = os.path.join(folder, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            class_index = class_names.index(class_name)\n",
    "            image_files = get_image_files(class_folder)\n",
    "            for image_file in image_files:\n",
    "                data.append({\n",
    "                    'image': image_file,\n",
    "                    'label': class_index,\n",
    "                })\n",
    "    return data, class_names\n",
    "\n",
    "\n",
    "def generate_dataset(folders):\n",
    "    all_data = []\n",
    "    for folder in folders:\n",
    "        data, class_names = load_images(folder)\n",
    "        all_data.extend(data)\n",
    "    features = Features({\n",
    "        # 'image': Value('string'),\n",
    "        'image': Array3D(dtype=\"uint8\", shape=(224, 224, 3)),\n",
    "        'label': ClassLabel(names=class_names)\n",
    "    })\n",
    "\n",
    "    data_dict = {\n",
    "        'image': [],\n",
    "        'label': []\n",
    "    }\n",
    "\n",
    "    for item in all_data:\n",
    "        try:\n",
    "            image = Image.open(item['image']).convert(\n",
    "                'RGB')  # Load and convert to RGB\n",
    "            # Resize to fit model input size (224x224)\n",
    "            image = image.resize((224, 224))\n",
    "            image_np = np.array(image)  # Convert PIL Image to numpy array\n",
    "            data_dict['image'].append(image_np)\n",
    "            data_dict['label'].append(item['label'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {item['image']}: {e}\")\n",
    "\n",
    "    return Dataset.from_dict(data_dict, features=features), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your dataset directories\n",
    "train_folder = '/home/eh_abdol/fine_tune/gold/train'\n",
    "validation_folder = '/home/eh_abdol/fine_tune/gold/validation'\n",
    "test_folder = '/home/eh_abdol/fine_tune/gold/test'\n",
    "\n",
    "# Generate the dataset\n",
    "dataset, class_names = generate_dataset(\n",
    "    [train_folder, validation_folder, test_folder])\n",
    "\n",
    "# Split the dataset into train, validation, and test\n",
    "train_data = dataset.filter(lambda x: x['image'].startswith(train_folder))\n",
    "validation_data = dataset.filter(\n",
    "    lambda x: x['image'].startswith(validation_folder))\n",
    "test_data = dataset.filter(lambda x: x['image'].startswith(test_folder))\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_data,\n",
    "    'validation': validation_data,\n",
    "    'test': test_data\n",
    "})\n",
    "\n",
    "# Save the combined dataset if you want to reuse it later\n",
    "dataset_dict.save_to_disk('/home/eh_abdol/fine_tune/gold_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 0\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the dataset\n",
    "dataset_dict = DatasetDict.load_from_disk(\n",
    "    '/home/eh_abdol/fine_tune/gold_dataset')\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (make sure the architecture is defined and matches the loaded model)\n",
    "model = VisionMamba(\n",
    "    patch_size=16,\n",
    "    stride=8,\n",
    "    embed_dim=384,\n",
    "    depth=24,\n",
    "    rms_norm=True,\n",
    "    residual_in_fp32=True,\n",
    "    fused_add_norm=True,\n",
    "    final_pool_type='mean',\n",
    "    if_abs_pos_embed=True,\n",
    "    if_rope=False,\n",
    "    if_rope_residual=False,\n",
    "    bimamba_type=\"v2\",\n",
    "    if_cls_token=True,\n",
    "    if_devide_out=True,\n",
    "    use_middle_cls_token=True,\n",
    "    num_classes=1000,  # Original number of classes\n",
    "    drop_rate=0.0,\n",
    "    drop_path_rate=0.1,\n",
    "    drop_block_rate=None,\n",
    "    img_size=224,\n",
    ")\n",
    "\n",
    "# Modify the head for binary classification\n",
    "model.head = nn.Linear(in_features=384, out_features=2)\n",
    "\n",
    "# Load the pretrained model weights\n",
    "checkpoint = torch.load(\"path/to/your/checkpoint.pth\", map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Fine-tuning loop\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader)}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "torch.save(model.state_dict(), \"fine_tuned_vision_mamba.pth\")\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Making a prediction\n",
    "with torch.no_grad():\n",
    "    test_image = Image.open(\"path/to/test/image.jpg\").convert(\"RGB\")\n",
    "    test_image = transform(test_image).unsqueeze(0).to(device)\n",
    "    prediction = model(test_image)\n",
    "    predicted_class = torch.argmax(prediction, dim=1).item()\n",
    "    print(f\"Predicted class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
